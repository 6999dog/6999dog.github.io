<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 爬虫的一次小练习（一） · Lu Gang</title><meta name="description" content="爬虫的一次小练习（一） - Lu Gang"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/css/prontera.css"><link rel="search" type="application/opensearchdescription+xml" href="http://6999dog.github.io/atom.xml" title="Lu Gang"><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Lu Gang" type="application/atom+xml">
</head><body><header class="feature-header"><nav class="component-nav"><ul><div class="logo-container"><a href="/"><h2 class="title">Lu Gang</h2></a></div><a href="/" target="_self" class="li component-nav-item"><p>INDEX</p></a><a href="/archives" target="_self" class="li component-nav-item"><p>ARCHIVES</p></a><ul class="shortcut-icons"><a href="https://github.com/AngryPowman" target="_blank"><img src="/images/github.svg" class="icon"></a><a href="/atom.xml" target="_blank"><img src="/images/rss.svg" class="icon"></a></ul></ul></nav></header><main class="container"><div id="post-container"><div class="post"><article class="post-block"><h1 class="post-title">爬虫的一次小练习（一）</h1><div class="post-info">Jun 6, 2020</div><div class="post-content"><p>今天小徐同学终于有了一个小侄女，以后要好好读书，给自己喜欢的宝贝买好多礼物</p>
<a id="more"></a>

<p>这个第一次写的爬虫遇到了不少问题<br>首先说明一下在本次的练习中使用到的库<br>我主要使用了正则表达式（re）、BeautuifulSoup4、requests<br>在本次的练习过程中我遇到了一些问题整理一下<br>1.我使用的discuz论坛，我的想法是爬取所有的帖子的主题，这里观察到翻页只改变页面的数字<br>  于是我做了一个随机数处理，但是注意的就是我刚刚开始没有进行字符串转换，所以一直在报错<br>2.在后期的处理中，我遇到了同样的问题，我得到一个整体的结果准备用正提取，但是没有成功，<br>  在我加入了循环并进行字符转换之后问题就解决了<br>话不多说，直接上代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">from lxml import html</span><br><span class="line">import xml</span><br><span class="line">import requests</span><br><span class="line">from lxml import etree</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">headers &#x3D; &#123;</span><br><span class="line">             &quot;User-Agent&quot;: &quot;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) </span><br><span class="line">             AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;80.0.3987.132 			</span><br><span class="line">             Safari&#x2F;537.36&quot;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">def find(a):</span><br><span class="line">    res &#x3D; r&#39;&lt;a .*?&gt;(.*?)&lt;&#x2F;a&gt;&#39;</span><br><span class="line">    mm &#x3D; re.findall(res, a, re.S | re.M)</span><br><span class="line">    for value in mm:</span><br><span class="line">        #save(value)</span><br><span class="line">        print(value)</span><br><span class="line"></span><br><span class="line">def save(mm):</span><br><span class="line">    with open(&#39;F:\Desktop\data.txt&#39;,&#39;a+&#39;)as fo:</span><br><span class="line">        fo.write(mm+&quot;\n&quot;)</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    for i in range(1, 20):</span><br><span class="line">        url1 &#x3D; &quot;https:&#x2F;&#x2F;www.discuz.net&#x2F;forum-developer-&quot;</span><br><span class="line">        url2 &#x3D; &quot;.html&quot;</span><br><span class="line">        url &#x3D; url1 + str(i) + url2</span><br><span class="line">        r &#x3D; requests.get(url, headers&#x3D;headers)</span><br><span class="line"></span><br><span class="line">        print(r.text)</span><br><span class="line"></span><br><span class="line">        soup &#x3D; BeautifulSoup(r.text, &#39;lxml&#39;)</span><br><span class="line">        a &#x3D; soup.find_all(onclick&#x3D;&quot;atarget(this)&quot;)</span><br><span class="line">        b &#x3D; soup.find_all()</span><br><span class="line">        a &#x3D; str(a)</span><br><span class="line">        b &#x3D; str(b)</span><br><span class="line">        #find(a)</span><br><span class="line">        find(b)</span><br><span class="line"></span><br><span class="line"> if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">     main()</span><br></pre></td></tr></table></figure></div></article></div><div id="disqus_thread"></div></div><script>var disqus_shortname = 'angrypowman';
var disqus_identifier = '2020/06/06/爬虫练习/';
var disqus_title = '爬虫的一次小练习（一）';
var disqus_url = 'http://6999dog.github.io/2020/06/06/爬虫练习/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//angrypowman.disqus.com/count.js" async></script></main><footer class="footer-container"><div class="paginator"><a href="/2020/06/09/wordcount%E7%BB%9F%E8%AE%A1/" class="prev">PREV</a><a href="/2020/04/20/%E9%87%8D%E6%96%B0%E6%8D%A1%E8%B5%B7c%E8%AF%AD%E8%A8%80%EF%BC%88%E4%BA%8C%EF%BC%89/" class="next">NEXT</a></div><div class="copyright"><p>© 2017 - 2020 <a href="http://6999dog.github.io">Lu Gang</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/AngryPowman/hexo-theme-prontera" target="_blank">hexo-theme-prontera</a>.</p></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"angrypowman",'auto');ga('send','pageview');</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"superSample":2,"width":200,"height":400,"position":"right","hOffset":0,"vOffset":-20},"mobile":{"show":true,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false});</script></body></html>